{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b154faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d0ca62",
   "metadata": {},
   "source": [
    "## Крестики-нолики при помощи Q-обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e854e4",
   "metadata": {},
   "source": [
    "Уже реализованное окружение для крестиков-ноликов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b577ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS, N_COLS, N_WIN = 3, 3, 3\n",
    "\n",
    "\n",
    "class TicTacToe(gym.Env):\n",
    "    def __init__(self, n_rows=N_ROWS, n_cols=N_COLS, n_win=N_WIN):\n",
    "        self.n_rows = n_rows\n",
    "        self.n_cols = n_cols\n",
    "        self.n_win = n_win\n",
    "\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.gameOver = False\n",
    "        self.boardHash = None\n",
    "        # ход первого игрока\n",
    "        self.curTurn = 1\n",
    "        self.emptySpaces = None\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def getEmptySpaces(self):\n",
    "        if self.emptySpaces is None:\n",
    "            res = np.where(self.board == 0)\n",
    "            self.emptySpaces = np.array([ (i, j) for i,j in zip(res[0], res[1]) ])\n",
    "        return self.emptySpaces\n",
    "\n",
    "    def makeMove(self, player, i, j):\n",
    "        self.board[i, j] = player\n",
    "        self.emptySpaces = None\n",
    "        self.boardHash = None\n",
    "\n",
    "    def getHash(self):\n",
    "        if self.boardHash is None:\n",
    "            self.boardHash = ''.join(['%s' % (x+1) for x in self.board.reshape(self.n_rows * self.n_cols)])\n",
    "        return self.boardHash\n",
    "\n",
    "    def _check_terminal(self, cur_p):\n",
    "        cur_marks = np.where(self.board == cur_p)\n",
    "        for i,j in zip(cur_marks[0], cur_marks[1]):\n",
    "            if i <= self.n_rows - self.n_win:\n",
    "                if np.all(self.board[i:i+self.n_win, j] == cur_p):\n",
    "                    return True\n",
    "            if j <= self.n_cols - self.n_win:\n",
    "                if np.all(self.board[i,j:j+self.n_win] == cur_p):\n",
    "                    return True\n",
    "            if i <= self.n_rows - self.n_win and j <= self.n_cols - self.n_win:\n",
    "                if np.all(np.array([ self.board[i+k,j+k] == cur_p for k in range(self.n_win) ])):\n",
    "                    return True\n",
    "            if i <= self.n_rows - self.n_win and j >= self.n_win-1:\n",
    "                if np.all(np.array([ self.board[i+k,j-k] == cur_p for k in range(self.n_win) ])):\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def isTerminal(self):\n",
    "        # проверим, не закончилась ли игра\n",
    "        cur_win = self._check_terminal(self.curTurn)\n",
    "        if cur_win:\n",
    "                self.gameOver = True\n",
    "                return self.curTurn\n",
    "            \n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "\n",
    "        self.gameOver = False\n",
    "        return None\n",
    "\n",
    "    def getWinner(self):\n",
    "        # фактически запускаем isTerminal два раза для крестиков и ноликов\n",
    "        if self._check_terminal(1):\n",
    "            return 1\n",
    "        if self._check_terminal(-1):\n",
    "            return -1\n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            return 0\n",
    "        return None\n",
    "    \n",
    "    def printBoard(self):\n",
    "        for i in range(0, self.n_rows):\n",
    "            print('----'*(self.n_cols)+'-')\n",
    "            out = '| '\n",
    "            for j in range(0, self.n_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----'*(self.n_cols)+'-')\n",
    "\n",
    "    def getState(self):\n",
    "        return (self.getHash(), self.getEmptySpaces(), self.curTurn)\n",
    "\n",
    "    def action_from_int(self, action_int):\n",
    "        return ( int(action_int / self.n_cols), int(action_int % self.n_cols))\n",
    "\n",
    "    def int_from_action(self, action):\n",
    "        return action[0] * self.n_cols + action[1]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.board[action[0], action[1]] != 0:\n",
    "            return self.getState(), -10, True, {}\n",
    "        self.makeMove(self.curTurn, action[0], action[1])\n",
    "        reward = self.isTerminal()\n",
    "        self.curTurn = -self.curTurn\n",
    "        return self.getState(), 0 if reward is None else reward, reward is not None, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.boardHash = None\n",
    "        self.gameOver = False\n",
    "        self.emptySpaces = None\n",
    "        self.curTurn = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996b59c",
   "metadata": {},
   "source": [
    "Оптимальные параметры для Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626e3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.15\n",
    "EPSILON = 0.2\n",
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b8c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_action(pi, state, empty_spaces, eps):\n",
    "    move = np.random.randint(len(empty_spaces))\n",
    "    if state in pi:\n",
    "        if random.random() > eps:\n",
    "            move = np.argmax(pi[state])\n",
    "    else:\n",
    "        pi[state] = np.zeros(len(empty_spaces))\n",
    "    return move, empty_spaces[move]\n",
    "\n",
    "\n",
    "def Q_learning(pi_crosses, pi_naughts, alpha, epsilon, gamma):\n",
    "    env.reset()\n",
    "    s, empty_spaces, turn = env.getState()\n",
    "    done = False\n",
    "    crosses_state,  crosses_action = None, None\n",
    "    naughts_state, naughts_action = None, None\n",
    "\n",
    "    while not done:\n",
    "        if turn == 1:\n",
    "            pi = pi_crosses\n",
    "            pi_rival = pi_naughts\n",
    "            state = crosses_state\n",
    "            action = crosses_action\n",
    "            state_rival = naughts_state\n",
    "            action_rival = naughts_action\n",
    "            needed_reward = 1\n",
    "        if turn == -1:\n",
    "            pi = pi_naughts\n",
    "            pi_rival = pi_crosses\n",
    "            state = naughts_state\n",
    "            action = naughts_action\n",
    "            state_rival = crosses_state\n",
    "            action_rival = crosses_action\n",
    "            needed_reward = -1\n",
    "\n",
    "        move, move_aсtion = pick_action(pi, s, empty_spaces, eps=epsilon)\n",
    "        new_state, reward, done, _ = env.step(move_aсtion)\n",
    "        if reward == needed_reward:\n",
    "            pi[s][move] = 1\n",
    "        if state_rival:\n",
    "            max_pi = np.max(pi_rival.get(new_state[0], 0))\n",
    "            pi_rival[state_rival][action_rival] = pi_rival[state_rival][action_rival] +\\\n",
    "            alpha * (- needed_reward * reward + gamma *  max_pi -  pi_rival[state_rival][action_rival])\n",
    "            \n",
    "        if turn == 1:\n",
    "            crosses_state, crosses_action = s, move\n",
    "        if turn == -1:\n",
    "            naughts_state, naughts_action = s, move\n",
    "            \n",
    "        s, empty_spaces, turn = new_state\n",
    "\n",
    "def play_game(pi_crosses, pi_naughts, game_type):\n",
    "    env.reset()\n",
    "    s, empty_spaces, turn = env.getState()\n",
    "    done = False\n",
    "    while not done:\n",
    "        Q = pi_crosses if game_type == 1 else pi_naughts\n",
    "        eps = 0 if game_type == turn else 1\n",
    "        move, move_aсtion = pick_action(Q, s, empty_spaces, eps=eps)\n",
    "        state, reward, done, _ = env.step(move_aсtion)\n",
    "        s, empty_spaces, turn = state\n",
    "    return reward\n",
    "\n",
    "\n",
    "def plot_stats(x, wins, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(x, wins)\n",
    "    plt.xlim(left=1)\n",
    "    plt.xlabel(\"Number of games\")\n",
    "    plt.ylabel(\"Frequency of win\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0d9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env_name, alpha, epsilon, gamma, n_iterations, iteration_check_stat, n_games_stat):\n",
    "    pi_crosses, pi_naughts = dict(), dict()\n",
    "    naughts_stat, crosses_stat = [], []\n",
    "\n",
    "    for i in tqdm(range(n_iterations)):\n",
    "        Q_learning(pi_crosses, pi_naughts, alpha=alpha, epsilon=epsilon, gamma=gamma)\n",
    "        if i % iteration_check_stat == 0: \n",
    "            current_naughts_stat, current_crosses_stat = [], []\n",
    "            for _ in range(n_games_stat):\n",
    "                current_naughts_stat.append(play_game(pi_crosses, pi_naughts, game_type=-1))\n",
    "                current_crosses_stat.append(play_game(pi_crosses, pi_naughts, game_type=1))\n",
    "            naughts_stat.append(current_naughts_stat.count(-1) / n_games_stat)\n",
    "            crosses_stat.append(current_crosses_stat.count(1) / n_games_stat)           \n",
    "            x_range.append(i)\n",
    "            \n",
    "    return naughts_stat, crosses_stat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2cc23",
   "metadata": {},
   "source": [
    "### Доска 3х3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261e874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▋                                 | 4811/100000 [00:05<01:09, 1366.98it/s]"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "epsilon = 0.7\n",
    "gamma = 0.95\n",
    "\n",
    "\n",
    "env = TicTacToe(3, 3, 3)\n",
    "env_name = \"3 * 3, 3\"\n",
    "\n",
    "x_range = []\n",
    "\n",
    "naughts_stat, crosses_stat = train(\n",
    "    env_name,\n",
    "    alpha=ALPHA,\n",
    "    epsilon=EPSILON,\n",
    "    gamma=GAMMA,\n",
    "    n_iterations=100_000,\n",
    "    iteration_check_stat=1_000,\n",
    "    n_games_stat=1000,\n",
    ")\n",
    "\n",
    "\n",
    "plot_stats(x_range, crosses_stat, \"Крестики vs random 3x3\")\n",
    "plot_stats(x_range, naughts_stat, \"Нолики vs random  3x3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588c8a4",
   "metadata": {},
   "source": [
    "Видим, что крестики выучились довольно хорошо - очень близко к 100%. Нолики - чуть похуже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed838025",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a7149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-dl",
   "language": "python",
   "name": "basic-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
